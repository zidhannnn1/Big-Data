{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m:[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10c25d6f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10c25d6f\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Hands-On Pertemuan 1: Pengenalan Big Data dan Overview Teknologi\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7117dfdb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7117dfdb\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Tujuan\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPada akhir praktikum ini, mahasiswa diharapkan mampu:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Memahami konsep dasar Big Data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7e805141\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7e805141\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Peralatan yang Dibutuhkan\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Anaconda (untuk manajemen lingkungan)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Jupyter Notebook (bawaan dari Anaconda)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. PySpark (untuk pemrosesan data skala besar)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. Pandas (untuk data analysis)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. Python (bawaan dari Anaconda)\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3xmH7-KgH-TH\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3xmH7-KgH-TH\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43mnull\u001b[49m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8daa78a0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8daa78a0\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Langkah-Langkah Hands-On\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m23b963c0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m23b963c0\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 1. Instalasi Anaconda\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 1: Unduh dan Instal Anaconda**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 2: Menginstal PySpark di Anaconda**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Setelah Anaconda terinstal, tambahkan PySpark:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```bash\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  pip install pyspark==3.4.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 3: Menginstal Pandas**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Untuk memudahkan data analysis, install Pandas:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```bash\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  pip install pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 4: Menginstal Findspark**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```bash\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  pip install findspark\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m208f1a45\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjp-MarkdownHeadingCollapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m:true,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m208f1a45\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 1: Membuka Jupyter Notebook**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Setelah instalasi selesai, buka Jupyter Notebook melalui Anaconda Navigator atau melalui terminal dengan perintah:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```bash\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  jupyter notebook\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 2: Membuat Project Notebook Baru**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Di Jupyter Notebook, buat notebook baru untuk praktikum ini.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Langkah 3: Praktik dengan PySpark**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Buat program sederhana untuk memulai dengan PySpark. Gunakan PySpark untuk membuat DataFrame dan memanipulasi data sederhana:\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport findspark\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfindspark.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERSZShIH_aN\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERSZShIH_aN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf78a5053\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf78a5053\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pyspark.sql import SparkSession\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Memulai Spark session\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark = SparkSession.builder.appName(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBigDataPractice\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m).getOrCreate()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Membuat DataFrame sederhana\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata = [(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAli\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 34), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBudi\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 23), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCitra\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 29), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDina\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 45)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns = [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf = spark.createDataFrame(data, columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menampilkan DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8747276f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8747276f\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 1**: Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1f84a333\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1f84a333\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 3. Praktik PySpark Lanjutan\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Latihan 1**: Memanipulasi Data dengan PySpark.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1f391ed5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1f391ed5\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pyspark.sql import SparkSession\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Memulai Spark session\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark = SparkSession.builder.appName(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBigDataPractice\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m).getOrCreate()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Membuat DataFrame sederhana\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata = [(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAli\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 34), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBudi\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 23), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCitra\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 29), (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDina\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, 45)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns = [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf = spark.createDataFrame(data, columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menampilkan DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Filtering data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_filtered = df.filter(df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] > 30)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_filtered.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menghitung rata-rata usia\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pyspark.sql.functions import avg\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf.groupBy().agg(avg(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)).show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Mengurutkan data berdasarkan usia\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_sorted = df.orderBy(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, ascending=False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_sorted.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me06767bc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me06767bc\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfe1e34a5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfe1e34a5\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 4. Praktik dengan Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Latihan 2**:  Buat DataFrame menggunakan Pandas:\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3f1f2ec1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3f1f2ec1\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Membuat DataFrame Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_pandas = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAli\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBudi\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCitra\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDina\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [34, 23, 29, 45]}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas = pd.DataFrame(data_pandas)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menampilkan DataFrame Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9da455f1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9da455f1\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc0042b2b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc0042b2b\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 5. Praktik Pandas Lanjutan\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Latihan 3**: Penggunaan Pandas untuk operasi lebih kompleks.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me7a8142f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me7a8142f\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Membuat DataFrame Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_pandas = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAli\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBudi\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCitra\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDina\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [34, 23, 29, 45]}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas = pd.DataFrame(data_pandas)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Membuat DataFrame kedua\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_pandas_2 = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAli\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBudi\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCitra\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDina\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPekerjaan\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDokter\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mGuru\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mInsinyur\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPerawat\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m]}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas_2 = pd.DataFrame(data_pandas_2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Join antara dua DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_joined = pd.merge(df_pandas, df_pandas_2, on=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNama\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(df_joined)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menghitung statistik deskriptif\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(df_pandas.describe())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Plotting Data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport matplotlib.pyplot as plt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsia\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].plot(kind=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m884ed75d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m884ed75d\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf671ba3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf671ba3\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 5. Menggabungkan PySpark dan Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Praktik untuk convert DataFrame dari PySpark ke Pandas dan sebaliknya:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m337e123f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m337e123f\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Mengonversi DataFrame dari PySpark ke Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas_from_spark = df.toPandas()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Mengonversi DataFrame dari Pandas ke PySpark\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_spark_from_pandas = spark.createDataFrame(df_pandas)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menampilkan DataFrame hasil konversi\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas_from_spark, df_spark_from_pandas.show()\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2cba4e5c\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2cba4e5c\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia.\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafdba6be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafdba6be\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 6. Konversi Data antara PySpark dan Pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m:null,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf863defc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf863defc\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Mengonversi DataFrame dari PySpark ke Pandas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas_from_spark = df.toPandas()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Mengonversi DataFrame dari Pandas ke PySpark\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_spark_from_pandas = spark.createDataFrame(df_pandas)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Menampilkan DataFrame hasil konversi\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_pandas_from_spark, df_spark_from_pandas.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m65adbe71\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m65adbe71\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia.\u001b[39m\u001b[38;5;124m\"\u001b[39m]}],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3 (ipykernel)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m3\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.11.9\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolab\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovenance\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}},\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m4\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m5\u001b[39m}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\"cells\":[{\"cell_type\":\"markdown\",\"id\":\"10c25d6f\",\"metadata\":{\"id\":\"10c25d6f\"},\"source\":[\"# Hands-On Pertemuan 1: Pengenalan Big Data dan Overview Teknologi\"]},{\"cell_type\":\"markdown\",\"id\":\"7117dfdb\",\"metadata\":{\"id\":\"7117dfdb\"},\"source\":[\"## Tujuan\\n\",\"Pada akhir praktikum ini, mahasiswa diharapkan mampu:\\n\",\"1. Memahami konsep dasar Big Data.\\n\",\"2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\\n\",\"3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\\n\",\"4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\\n\",\"5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas.\"]},{\"cell_type\":\"markdown\",\"id\":\"7e805141\",\"metadata\":{\"id\":\"7e805141\"},\"source\":[\"## Peralatan yang Dibutuhkan\\n\",\"1. Anaconda (untuk manajemen lingkungan)\\n\",\"2. Jupyter Notebook (bawaan dari Anaconda)\\n\",\"3. PySpark (untuk pemrosesan data skala besar)\\n\",\"4. Pandas (untuk data analysis)\\n\",\"5. Python (bawaan dari Anaconda)\"]},{\"cell_type\":\"code\",\"source\":[],\"metadata\":{\"id\":\"3xmH7-KgH-TH\"},\"id\":\"3xmH7-KgH-TH\",\"execution_count\":null,\"outputs\":[]},{\"cell_type\":\"markdown\",\"id\":\"8daa78a0\",\"metadata\":{\"id\":\"8daa78a0\"},\"source\":[\"## Langkah-Langkah Hands-On\"]},{\"cell_type\":\"markdown\",\"id\":\"23b963c0\",\"metadata\":{\"id\":\"23b963c0\"},\"source\":[\"### 1. Instalasi Anaconda\\n\",\"- **Langkah 1: Unduh dan Instal Anaconda**\\n\",\"  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\\n\",\"  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\\n\",\"  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\\n\",\"\\n\",\"- **Langkah 2: Menginstal PySpark di Anaconda**\\n\",\"  Setelah Anaconda terinstal, tambahkan PySpark:\\n\",\"  ```bash\\n\",\"  pip install pyspark==3.4.1\\n\",\"  ```\\n\",\"\\n\",\"- **Langkah 3: Menginstal Pandas**\\n\",\"  Untuk memudahkan data analysis, install Pandas:\\n\",\"  ```bash\\n\",\"  pip install pandas\\n\",\"  ```\\n\",\"\\n\",\"- **Langkah 4: Menginstal Findspark**\\n\",\"  ```bash\\n\",\"  pip install findspark\\n\",\"  ```\"]},{\"cell_type\":\"markdown\",\"id\":\"208f1a45\",\"metadata\":{\"jp-MarkdownHeadingCollapsed\":true,\"id\":\"208f1a45\"},\"source\":[\"### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas\\n\",\"- **Langkah 1: Membuka Jupyter Notebook**\\n\",\"  Setelah instalasi selesai, buka Jupyter Notebook melalui Anaconda Navigator atau melalui terminal dengan perintah:\\n\",\"  ```bash\\n\",\"  jupyter notebook\\n\",\"  ```\\n\",\"\\n\",\"- **Langkah 2: Membuat Project Notebook Baru**\\n\",\"  Di Jupyter Notebook, buat notebook baru untuk praktikum ini.\\n\",\"\\n\",\"- **Langkah 3: Praktik dengan PySpark**\\n\",\"  Buat program sederhana untuk memulai dengan PySpark. Gunakan PySpark untuk membuat DataFrame dan memanipulasi data sederhana:\"]},{\"cell_type\":\"code\",\"source\":[\"import findspark\\n\",\"findspark.init()\"],\"metadata\":{\"id\":\"KERSZShIH_aN\"},\"id\":\"KERSZShIH_aN\",\"execution_count\":null,\"outputs\":[]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"f78a5053\",\"metadata\":{\"id\":\"f78a5053\"},\"outputs\":[],\"source\":[\"from pyspark.sql import SparkSession\\n\",\"\\n\",\"# Memulai Spark session\\n\",\"spark = SparkSession.builder.appName(\\\"BigDataPractice\\\").getOrCreate()\\n\",\"\\n\",\"# Membuat DataFrame sederhana\\n\",\"data = [(\\\"Ali\\\", 34), (\\\"Budi\\\", 23), (\\\"Citra\\\", 29), (\\\"Dina\\\", 45)]\\n\",\"columns = [\\\"Nama\\\", \\\"Usia\\\"]\\n\",\"df = spark.createDataFrame(data, columns)\\n\",\"\\n\",\"# Menampilkan DataFrame\\n\",\"df.show()\\n\"]},{\"cell_type\":\"markdown\",\"id\":\"8747276f\",\"metadata\":{\"id\":\"8747276f\"},\"source\":[\"- **Tugas 1**: Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender.\"]},{\"cell_type\":\"markdown\",\"id\":\"1f84a333\",\"metadata\":{\"id\":\"1f84a333\"},\"source\":[\"### 3. Praktik PySpark Lanjutan\\n\",\"- **Latihan 1**: Memanipulasi Data dengan PySpark.\"]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"1f391ed5\",\"metadata\":{\"id\":\"1f391ed5\"},\"outputs\":[],\"source\":[\"from pyspark.sql import SparkSession\\n\",\"\\n\",\"# Memulai Spark session\\n\",\"spark = SparkSession.builder.appName(\\\"BigDataPractice\\\").getOrCreate()\\n\",\"\\n\",\"# Membuat DataFrame sederhana\\n\",\"data = [(\\\"Ali\\\", 34), (\\\"Budi\\\", 23), (\\\"Citra\\\", 29), (\\\"Dina\\\", 45)]\\n\",\"columns = [\\\"Nama\\\", \\\"Usia\\\"]\\n\",\"df = spark.createDataFrame(data, columns)\\n\",\"\\n\",\"# Menampilkan DataFrame\\n\",\"df.show()\\n\",\"\\n\",\"# Filtering data\\n\",\"df_filtered = df.filter(df['Usia'] > 30)\\n\",\"df_filtered.show()\\n\",\"\\n\",\"# Menghitung rata-rata usia\\n\",\"from pyspark.sql.functions import avg\\n\",\"df.groupBy().agg(avg(\\\"Usia\\\")).show()\\n\",\"\\n\",\"# Mengurutkan data berdasarkan usia\\n\",\"df_sorted = df.orderBy(\\\"Usia\\\", ascending=False)\\n\",\"df_sorted.show()\\n\"]},{\"cell_type\":\"markdown\",\"id\":\"e06767bc\",\"metadata\":{\"id\":\"e06767bc\"},\"source\":[\"- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark.\"]},{\"cell_type\":\"markdown\",\"id\":\"fe1e34a5\",\"metadata\":{\"id\":\"fe1e34a5\"},\"source\":[\"### 4. Praktik dengan Pandas\\n\",\"- **Latihan 2**:  Buat DataFrame menggunakan Pandas:\"]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"3f1f2ec1\",\"metadata\":{\"id\":\"3f1f2ec1\"},\"outputs\":[],\"source\":[\"import pandas as pd\\n\",\"\\n\",\"# Membuat DataFrame Pandas\\n\",\"data_pandas = {\\\"Nama\\\": [\\\"Ali\\\", \\\"Budi\\\", \\\"Citra\\\", \\\"Dina\\\"], \\\"Usia\\\": [34, 23, 29, 45]}\\n\",\"df_pandas = pd.DataFrame(data_pandas)\\n\",\"\\n\",\"# Menampilkan DataFrame Pandas\\n\",\"df_pandas\"]},{\"cell_type\":\"markdown\",\"id\":\"9da455f1\",\"metadata\":{\"id\":\"9da455f1\"},\"source\":[\"- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia.\"]},{\"cell_type\":\"markdown\",\"id\":\"c0042b2b\",\"metadata\":{\"id\":\"c0042b2b\"},\"source\":[\"### 5. Praktik Pandas Lanjutan\\n\",\"- **Latihan 3**: Penggunaan Pandas untuk operasi lebih kompleks.\"]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"e7a8142f\",\"metadata\":{\"id\":\"e7a8142f\"},\"outputs\":[],\"source\":[\"import pandas as pd\\n\",\"\\n\",\"# Membuat DataFrame Pandas\\n\",\"data_pandas = {\\\"Nama\\\": [\\\"Ali\\\", \\\"Budi\\\", \\\"Citra\\\", \\\"Dina\\\"], \\\"Usia\\\": [34, 23, 29, 45]}\\n\",\"df_pandas = pd.DataFrame(data_pandas)\\n\",\"\\n\",\"# Membuat DataFrame kedua\\n\",\"data_pandas_2 = {\\\"Nama\\\": [\\\"Ali\\\", \\\"Budi\\\", \\\"Citra\\\", \\\"Dina\\\"], \\\"Pekerjaan\\\": [\\\"Dokter\\\", \\\"Guru\\\", \\\"Insinyur\\\", \\\"Perawat\\\"]}\\n\",\"df_pandas_2 = pd.DataFrame(data_pandas_2)\\n\",\"\\n\",\"# Join antara dua DataFrame\\n\",\"df_joined = pd.merge(df_pandas, df_pandas_2, on=\\\"Nama\\\")\\n\",\"print(df_joined)\\n\",\"\\n\",\"# Menghitung statistik deskriptif\\n\",\"print(df_pandas.describe())\\n\",\"\\n\",\"# Plotting Data\\n\",\"import matplotlib.pyplot as plt\\n\",\"df_pandas['Usia'].plot(kind='bar')\\n\",\"plt.show()\\n\"]},{\"cell_type\":\"markdown\",\"id\":\"884ed75d\",\"metadata\":{\"id\":\"884ed75d\"},\"source\":[\"- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas.\"]},{\"cell_type\":\"markdown\",\"id\":\"bf671ba3\",\"metadata\":{\"id\":\"bf671ba3\"},\"source\":[\"### 5. Menggabungkan PySpark dan Pandas\\n\",\"- **Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas**\\n\",\"  Praktik untuk convert DataFrame dari PySpark ke Pandas dan sebaliknya:\\n\"]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"337e123f\",\"metadata\":{\"id\":\"337e123f\"},\"outputs\":[],\"source\":[\"# Mengonversi DataFrame dari PySpark ke Pandas\\n\",\"df_pandas_from_spark = df.toPandas()\\n\",\"\\n\",\"# Mengonversi DataFrame dari Pandas ke PySpark\\n\",\"df_spark_from_pandas = spark.createDataFrame(df_pandas)\\n\",\"\\n\",\"# Menampilkan DataFrame hasil konversi\\n\",\"df_pandas_from_spark, df_spark_from_pandas.show()\"]},{\"cell_type\":\"markdown\",\"id\":\"2cba4e5c\",\"metadata\":{\"id\":\"2cba4e5c\"},\"source\":[\"- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia.\"]},{\"cell_type\":\"markdown\",\"id\":\"afdba6be\",\"metadata\":{\"id\":\"afdba6be\"},\"source\":[\"### 6. Konversi Data antara PySpark dan Pandas\"]},{\"cell_type\":\"code\",\"execution_count\":null,\"id\":\"f863defc\",\"metadata\":{\"id\":\"f863defc\"},\"outputs\":[],\"source\":[\"# Mengonversi DataFrame dari PySpark ke Pandas\\n\",\"df_pandas_from_spark = df.toPandas()\\n\",\"\\n\",\"# Mengonversi DataFrame dari Pandas ke PySpark\\n\",\"df_spark_from_pandas = spark.createDataFrame(df_pandas)\\n\",\"\\n\",\"# Menampilkan DataFrame hasil konversi\\n\",\"df_pandas_from_spark, df_spark_from_pandas.show()\\n\"]},{\"cell_type\":\"markdown\",\"id\":\"65adbe71\",\"metadata\":{\"id\":\"65adbe71\"},\"source\":[\"- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia.\"]}],\"metadata\":{\"kernelspec\":{\"display_name\":\"Python 3 (ipykernel)\",\"language\":\"python\",\"name\":\"python3\"},\"language_info\":{\"codemirror_mode\":{\"name\":\"ipython\",\"version\":3},\"file_extension\":\".py\",\"mimetype\":\"text/x-python\",\"name\":\"python\",\"nbconvert_exporter\":\"python\",\"pygments_lexer\":\"ipython3\",\"version\":\"3.11.9\"},\"colab\":{\"provenance\":[]}},\"nbformat\":4,\"nbformat_minor\":5}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
